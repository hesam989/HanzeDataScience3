{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Text clustering\n",
    "\n",
    "Read, execute and analyse the code in the notebook tutorial_clustering_words. Then *choose one* of the assignments\n",
    " a), b) or c). \n",
    "\n",
    "a) read the article Clinical Documents Clustering Based on Medication/Symptom Names Using Multi-View Nonnegative Matrix Factorization. \n",
    "you can find the article <a href = 'https://pubmed.ncbi.nlm.nih.gov/26011887/'> here</a>. Explain the similarities of this notebook and\n",
    " the article. Explain in your own words what need to be added to this notebook to reproduce the article. There is no need to code the solution\n",
    " , you can mention in your own words the steps. \n",
    "\n",
    "b) Improve the outcome improving the data preprocessing and the hyper parameter configurations. \n",
    "Explain your choices. Your solution should be a coded solution with comments. \n",
    "Are there any other weighting solutions next to TF-IDF?\n",
    "\n",
    "c) Provide a text clustering solution with your own data of interest, you can follow a similar approach to the one in the\n",
    " tutorial_clustering_words notebook. \n",
    "\n",
    "Mind you that you are not allowed to copy code solutions without referencing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Solution W2: Part a </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities:\n",
    "\n",
    "1. Both methods use a collection of clinical case reports or clinical notes for their analysis.\n",
    "\n",
    "2. They both involve preprocessing of the text which includes removing punctuations, stop words, and other unwanted text, as well as lowercasing the text.\n",
    "it is worth metioning that it does not mention exactly do in preprocessing part in paper two, but because \"removing punctuations, stop words, and other unwanted text\" is standard procedure I assume they did the same\n",
    "\n",
    "3. Both methods use Nonnegative Matrix Factorization (NMF) for clustering. This involves creating a Document-Term Matrix (DTM) or similar matrices (like sample-feature matrices in method two) to perform the calculations.\n",
    "\n",
    "\n",
    "## Differences and what needs to be added to method one to reproduce method two:\n",
    "\n",
    "1. Entity Extraction: In method two, the researchers specifically extract entities like symptom names and medication names from the clinical notes using specialized tools such as Stanford CoreNLP, MetaMap, and MedEx. Method one does not have this step. To reproduce method two, method one would need to add a step to extract specific entities like symptom names and medication names.\n",
    "\n",
    "2. Multi-view NMF: Method two uses an extension of NMF, called multi-view NMF, that considers different 'views' or perspectives of the data simultaneously. To reproduce method two, method one would need to incorporate the use of multi-view NMF instead of just basic NMF.\n",
    "\n",
    "3. Data Sources: Method two uses two different datasets from i2b2 workshop on NLP challenges, from 2009 and 2014 respectively, whereas method one does not specify the data source. To reproduce method two, the first method would need to use the same or comparable datasets.\n",
    "\n",
    "4. Evaluation Metrics: Method two uses specific metrics such as accuracy and normalized mutual information (NMI) to evaluate the clustering results. Method one does not specify any evaluation metrics. To reproduce method two, method one would need to include these evaluation metrics.\n",
    "\n",
    "5. Negation Processing: Method two involves identifying negations in the clinical notes, to exclude certain symptom and medication names. Method one does not mention handling negations. This could be a crucial addition to method one to replicate the results of method two.\n",
    "\n",
    "6. Different Feature Spaces: Method two generates features from three views: symptom names, medication names, and words, whereas method one only uses the lemmatized words for feature extraction. To reproduce method two, method one would need to generate features from these additional perspectives.\n",
    "\n",
    "## conclusion\n",
    "Conclusion, method one can be considered a simpler approach to text clustering, while method two is more nuanced and takes into account multiple views of the data, extracts specific entities, and uses specific evaluation metrics. To reproduce method two, method one would need to incorporate these additional steps and considerations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Implenting method one with \"MACCROBAT2020\" Dataset </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering text\n",
    "\n",
    "See also https://towardsdatascience.com/nmf-a-visual-explainer-and-python-implementation-7ecdd73491f8\n",
    "\n",
    "\n",
    "This notebook uses a collection of clinical case reports to cluster words by topics using the NMF method. To cluster text we need to preprocess the text first with regular natural language processing cleaning steps such as remove punctuations, stopwords, or other unwanted text. we lower the text and use the lemma to reduce variation of words. This is all done in part A. \n",
    "\n",
    "Next we need to prepare the text in a document term matrix so that NMF can perform the calculations. The Document-Term Matrix (DTM) represents the frequency of words (or terms) in a collection of documents. Each row in the matrix represents a document, and each column represents a word in the vocabulary. The value in each cell represents the frequency of the corresponding word in the corresponding document. This is done in part B\n",
    "\n",
    "Lastly we run the clustering algorithm and visualize the outcome. This is done in part C\n",
    "\n",
    "\n",
    "## The data \n",
    "A collection of 200 clinical case report documents in plain text format are used. The documents are named using PubMed document IDs, and have been edited to include only clinical case report details. The dataset is called \"MACCROBAT2020\" and is the second release of this dataset, with improvements made to the consistency and format of annotations\n",
    "https://figshare.com/articles/dataset/MACCROBAT2018/9764942\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rom sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19860925.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26228535.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27773410.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28103924.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27064109.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/20146086.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26656340.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22515939.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353588.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26309459.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28272235.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23242090.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23124805.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26106249.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18416479.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26175648.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28216610.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23077697.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21067996.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28100235.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25884600.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19214295.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22719160.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28422883.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25139918.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353561.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22791498.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27842605.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28403092.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28239141.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28202869.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25024632.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28403086.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25572898.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28296775.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22514576.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28296749.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23468586.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27059701.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28151916.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353613.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26285706.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26313770.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23312850.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353558.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28154700.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25853982.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23678274.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26361640.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26584481.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18666334.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26469535.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353604.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25155594.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/20671919.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26457578.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28538413.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21477357.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26675562.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18787726.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28151860.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27904130.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27741115.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28121940.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19860007.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28193213.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28120581.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28057913.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/20977862.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25721834.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19860006.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28207542.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23864579.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26361431.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25370695.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26683938.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25023062.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25293719.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18561524.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26444414.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23035161.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24898994.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28265107.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26670309.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26530965.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26336183.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25410883.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26523273.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25743872.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28190872.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/16778410.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21923918.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22814979.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22665582.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21308977.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28248858.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27218632.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18258107.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28100279.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26264228.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23155491.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19816630.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25858931.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28090049.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28115731.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24294397.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27683825.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28196820.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18236639.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28033278.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21254744.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26266396.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24518095.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26350418.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/15939911.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27980261.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25759562.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27821134.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23033875.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28173879.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21527041.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21505579.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28250406.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26405496.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27661040.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27196481.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24957905.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26216058.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28079821.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28248891.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21672201.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25661749.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/17803823.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24526194.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27974938.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25210224.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26629302.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25934795.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24781756.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23076693.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/18815636.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25926582.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27980272.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/23897372.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28403099.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28202862.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28154281.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25246819.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353556.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28272214.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19307547.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27990013.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27906105.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24043987.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24654246.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19009665.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28767567.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/19610147.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26692730.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27793101.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353569.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27057898.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26327988.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28353596.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21129213.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28559815.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28292056.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/21720478.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28383413.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27842595.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28321071.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27998312.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28154287.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26445413.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26664317.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26257516.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22218279.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28154669.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27130218.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26474553.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28595573.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28321070.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28202865.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28320420.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25295501.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25410034.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26714786.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28250304.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27749582.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/24161539.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/25793030.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/26395443.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22520024.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27846860.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27928148.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28151882.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27004009.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/27100441.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/28321073.txt', '/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/22781096.txt']\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/Hesam_1/Library/CloudStorage/OneDrive-H...</td>\n",
       "      <td>Our 24-year-old non-smoking male patient prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/Hesam_1/Library/CloudStorage/OneDrive-H...</td>\n",
       "      <td>A 25-year-old female patient had noticed left-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/Hesam_1/Library/CloudStorage/OneDrive-H...</td>\n",
       "      <td>A 69-year-old male diabetic patient was admitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/Hesam_1/Library/CloudStorage/OneDrive-H...</td>\n",
       "      <td>Our patient was a 7-year-old Italian boy born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/Hesam_1/Library/CloudStorage/OneDrive-H...</td>\n",
       "      <td>A 53-year-old man came to our hospital with si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               docid  \\\n",
       "0  /Users/Hesam_1/Library/CloudStorage/OneDrive-H...   \n",
       "1  /Users/Hesam_1/Library/CloudStorage/OneDrive-H...   \n",
       "2  /Users/Hesam_1/Library/CloudStorage/OneDrive-H...   \n",
       "3  /Users/Hesam_1/Library/CloudStorage/OneDrive-H...   \n",
       "4  /Users/Hesam_1/Library/CloudStorage/OneDrive-H...   \n",
       "\n",
       "                                                text  \n",
       "0  Our 24-year-old non-smoking male patient prese...  \n",
       "1  A 25-year-old female patient had noticed left-...  \n",
       "2  A 69-year-old male diabetic patient was admitt...  \n",
       "3  Our patient was a 7-year-old Italian boy born ...  \n",
       "4  A 53-year-old man came to our hospital with si...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import string\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#create empty dataframe\n",
    "df = pd.DataFrame(columns=['docid','text'])\n",
    "\n",
    "# Get all files ending with .txt\n",
    "docs = [x for x in glob.glob(\"/Users/Hesam_1/Library/CloudStorage/OneDrive-HanzehogeschoolGroningen/Semester2/MachineLearning/Data/MACCROBAT2020/*.txt\")]\n",
    "\n",
    "# Fill dataframe\n",
    "for doc in docs:\n",
    "    txt = Path(doc).read_text()\n",
    "    df.loc[len(df.index)] = [doc[:-4], txt]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, \n",
    "    remove punctuation, remove read errors,\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
    "    text = re.sub('�', ' ', text)\n",
    "    return text\n",
    "\n",
    "cleaned = lambda x: clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun extract and lemmatize function\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text \n",
    "    and pull out only the nouns.'''\n",
    "    # create mask to isolate words that are nouns\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    # store function to split string of words \n",
    "    # into a list of words (tokens)\n",
    "    tokenized = word_tokenize(text)\n",
    "    # store function to lemmatize each word\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    # use list comprehension to lemmatize all words \n",
    "    # and create a list of all nouns\n",
    "    all_nouns = [wordnet_lemmatizer.lemmatize(word) \\\n",
    "    for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    \n",
    "    #return string of joined list of nouns\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year non patient hemoptysis day thoracic pain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year female patient loss year hemiparesis mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year patient failure therapy edema basal crepi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient year boy gestation duration age month ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year man hospital sign symptom heart failure w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  year non patient hemoptysis day thoracic pain ...\n",
       "1  year female patient loss year hemiparesis mont...\n",
       "2  year patient failure therapy edema basal crepi...\n",
       "3  patient year boy gestation duration age month ...\n",
       "4  year man hospital sign symptom heart failure w..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Text\n",
    "df[\"text\"] = df[\"text\"].apply(cleaned)\n",
    "data_nouns = pd.DataFrame(df[\"text\"].apply(nouns))\n",
    "# Visually Inspect\n",
    "data_nouns.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: The Document-Term Matrix (DTM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdomen</th>\n",
       "      <th>ablation</th>\n",
       "      <th>abnormality</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>abuse</th>\n",
       "      <th>access</th>\n",
       "      <th>accompanying</th>\n",
       "      <th>accordance</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>yr</th>\n",
       "      <th>zhejiang</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>µg</th>\n",
       "      <th>µmol</th>\n",
       "      <th>μg</th>\n",
       "      <th>μl</th>\n",
       "      <th>μmol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1959 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abdomen  ablation  abnormality   abscess   absence  absent  abuse  access  \\\n",
       "0  0.000000       0.0          0.0  0.000000  0.000000     0.0    0.0     0.0   \n",
       "1  0.000000       0.0          0.0  0.000000  0.056135     0.0    0.0     0.0   \n",
       "2  0.000000       0.0          0.0  0.000000  0.000000     0.0    0.0     0.0   \n",
       "3  0.055374       0.0          0.0  0.000000  0.000000     0.0    0.0     0.0   \n",
       "4  0.000000       0.0          0.0  0.080138  0.000000     0.0    0.0     0.0   \n",
       "\n",
       "   accompanying  accordance  ...      york   yr  zhejiang  zinc  zone   µg  \\\n",
       "0           0.0         0.0  ...  0.000000  0.0       0.0   0.0   0.0  0.0   \n",
       "1           0.0         0.0  ...  0.000000  0.0       0.0   0.0   0.0  0.0   \n",
       "2           0.0         0.0  ...  0.000000  0.0       0.0   0.0   0.0  0.0   \n",
       "3           0.0         0.0  ...  0.000000  0.0       0.0   0.0   0.0  0.0   \n",
       "4           0.0         0.0  ...  0.083947  0.0       0.0   0.0   0.0  0.0   \n",
       "\n",
       "   µmol        μg   μl  μmol  \n",
       "0   0.0  0.000000  0.0   0.0  \n",
       "1   0.0  0.000000  0.0   0.0  \n",
       "2   0.0  0.000000  0.0   0.0  \n",
       "3   0.0  0.000000  0.0   0.0  \n",
       "4   0.0  0.062559  0.0   0.0  \n",
       "\n",
       "[5 rows x 1959 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document-term matrix with only nouns\n",
    "# Store TF-IDF Vectorizer\n",
    "tv_noun = TfidfVectorizer(stop_words='english', ngram_range = (1,1), max_df = .8, min_df = .01)\n",
    "# Fit and Transform speech noun text to a TF-IDF Doc-Term Matrix\n",
    "data_tv_noun = tv_noun.fit_transform(data_nouns.text)\n",
    "# Create data-frame of Doc-Term Matrix with nouns as column names\n",
    "data_dtm_noun = pd.DataFrame(data_tv_noun.toarray(), columns=tv_noun.get_feature_names_out())\n",
    "data_dtm_noun.index = df.index\n",
    "# Visually inspect Document Term Matrix\n",
    "data_dtm_noun.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Run the NMF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_top_words, topic_names=None):\n",
    "    '''Given an NMF model, feature_names, and number of top words, print \n",
    "       topic number and its top feature names, up to specified number of top words.'''\n",
    "    # iterate through topics in topic-term matrix, 'H' aka\n",
    "    # model.components_\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        #print topic, topic number, and top words\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i] \\\n",
    "             for i in topic.argsort()[:-num_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "dl, mg, level, blood, ml, day, count, platelet, serum, range\n",
      "\n",
      "Topic  1\n",
      "tumor, mass, cell, cm, lesion, figure, fig, lymph, resection, metastasis\n",
      "\n",
      "Topic  2\n",
      "valve, figure, echocardiography, heart, artery, mm, pressure, failure, atrium, vein\n",
      "\n",
      "Topic  3\n",
      "lung, day, chest, fig, treatment, hospital, tuberculosis, therapy, effusion, dyspnea\n",
      "\n",
      "Topic  4\n",
      "age, month, eye, week, seizure, rash, parent, mri, muscle, brain\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(5)\n",
    "# Learn an NMF model for given Document Term Matrix 'V' \n",
    "# Extract the document-topic matrix 'W'\n",
    "doc_topic = nmf_model.fit_transform(data_dtm_noun)\n",
    "# Extract top words from the topic-term matrix 'H' \n",
    "display_topics(nmf_model, tv_noun.get_feature_names_out(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
